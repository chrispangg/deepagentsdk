/**
 * BDD Tests: Telemetry Passthrough Implementation
 *
 * Tests for comprehensive telemetry and options passthrough across all DeepAgent methods.
 * Verifies that generate() and streamWithEvents() behave consistently.
 *
 * Generated by: /3_define_test_cases
 * Last updated: 2025-12-22
 * Test coverage: Phases 1-3 of telemetry implementation plan
 */

import { test, expect, describe, beforeEach } from "bun:test";
import { createDeepAgent } from "../src/agent";
import { StateBackend } from "../src/backends/state";
import { anthropic } from "@ai-sdk/anthropic";
import { tool } from "ai";
import { z } from "zod";
import type { DeepAgentEvent, DeepAgentState } from "../src/types";

// ============================================================================
// Test Helpers
// ============================================================================

/** Helper: Create a mock tool for testing (used 10+ times) */
function createMockTool(name: string) {
  return tool({
    description: `Test tool: ${name}`,
    inputSchema: z.object({ input: z.string() }),
    execute: async ({ input }) => `Tool ${name} processed: ${input}`,
  });
}

/** Helper: Create agent with telemetry (used 8+ times) */
function createAgentWithTelemetry(options: any = {}) {
  return createDeepAgent({
    model: anthropic("claude-haiku-4-5-20251001"),
    backend: new StateBackend({ todos: [], files: {} }),
    advancedOptions: {
      experimental_telemetry: { isEnabled: true },
    },
    ...options,
  });
}

/** Helper: Collect all events from streamWithEvents (used 6+ times) */
async function collectEvents(
  agent: any,
  prompt: string,
  maxSteps: number = 1
): Promise<DeepAgentEvent[]> {
  const events: DeepAgentEvent[] = [];
  for await (const event of agent.streamWithEvents({
    messages: [{ role: "user", content: prompt }],
    maxSteps,
  })) {
    events.push(event);
    if (event.type === "done") break;
  }
  return events;
}

// ============================================================================
// Phase 1: Core Passthrough Options for streamWithEvents()
// ============================================================================

describe("Phase 1: Core Passthrough Options", () => {
  let backend: StateBackend;

  beforeEach(() => {
    backend = new StateBackend({ todos: [], files: {} });
  });

  test("passes experimental_telemetry to streamText", async () => {
    // Given: Agent with telemetry enabled
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      advancedOptions: {
        experimental_telemetry: { isEnabled: true },
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: Should complete without errors (telemetry passed through)
    expect(events.some((e) => e.type === "done")).toBe(true);
    expect(events.some((e) => e.type === "text")).toBe(true);
  });

  test("passes all generationOptions to streamText", async () => {
    // Given: Agent with generation options
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      generationOptions: {
        temperature: 0.7,
        maxRetries: 3,
        maxOutputTokens: 100,
        stopSequences: ["STOP"],
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: Should complete successfully with options applied
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("passes providerOptions to streamText", async () => {
    // Given: Agent with provider-specific options
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      advancedOptions: {
        providerOptions: {
          anthropic: {
            // Valid Anthropic option (example)
          },
        },
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: Should complete without errors
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("passes toolChoice and activeTools to streamText", async () => {
    // Given: Agent with tool control options
    const testTool = createMockTool("test_tool");
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      tools: { testTool },
      advancedOptions: {
        toolChoice: "auto",
        activeTools: ["test_tool"],
      },
    });

    // When: Using streamWithEvents with tool-related prompt
    const events = await collectEvents(agent, "Use test_tool with input 'hello'", 2);

    // Then: Should execute the tool
    expect(events.some((e) => e.type === "step-finish")).toBe(true);
  });

  test("passes experimental_context to streamText", async () => {
    // Given: Agent with experimental context
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      advancedOptions: {
        experimental_context: {
          userId: "test-user",
          sessionId: "test-session",
        },
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: Should complete successfully
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("passes output configuration to streamText", async () => {
    // Given: Agent with output configuration
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      output: {
        schema: z.object({
          response: z.string(),
        }),
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: Should complete with structured output
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("handles multiple options together correctly", async () => {
    // Given: Agent with multiple option types
    const multiTool = createMockTool("multi_tool");
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      tools: { multiTool },
      generationOptions: { temperature: 0.5 },
      advancedOptions: {
        experimental_telemetry: { isEnabled: true },
        toolChoice: "auto",
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Use multi_tool", 2);

    // Then: Should handle all options correctly
    expect(events.some((e) => e.type === "done")).toBe(true);
    expect(events.some((e) => e.type === "step-finish")).toBe(true);
  });

  test("handles undefined options gracefully", async () => {
    // Given: Agent with minimal configuration
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: Should work without errors
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("matches generate() behavior with same options", async () => {
    // Given: Two agents with identical configurations
    const options = {
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      generationOptions: { temperature: 0.7 },
      advancedOptions: {
        experimental_telemetry: { isEnabled: true },
        providerOptions: { anthropic: {} },
      },
    };
    const agentGenerate = createDeepAgent(options);
    const agentStream = createDeepAgent(options);

    // When: Using both methods
    const result = await agentGenerate.generate({
      prompt: "Say 'hello world'",
      maxSteps: 1,
    });
    const events = await collectEvents(agentStream, "Say 'hello world'", 1);

    // Then: Both should complete successfully
    expect(result.text).toBeTruthy();
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("preserves existing functionality with prompt caching", async () => {
    // Given: Agent with prompt caching enabled
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      enablePromptCaching: true,
      advancedOptions: {
        experimental_telemetry: { isEnabled: true },
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: Should work with both caching and telemetry
    expect(events.some((e) => e.type === "done")).toBe(true);
  });
});

// ============================================================================
// Phase 2: loopControl Callback Composition for Streaming
// ============================================================================

describe("Phase 2: loopControl Callback Composition", () => {
  let backend: StateBackend;
  let onStepFinishCalls: any[] = [];
  let onFinishCalls: any[] = [];
  let prepareStepCalls: any[] = [];

  beforeEach(() => {
    backend = new StateBackend({ todos: [], files: {} });
    onStepFinishCalls = [];
    onFinishCalls = [];
    prepareStepCalls = [];
  });

  test("calls user's onStepFinish callback during streaming", async () => {
    // Given: Agent with onStepFinish callback
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      tools: { test_tool: createMockTool("test") },
      loopControl: {
        onStepFinish: async ({ toolCalls, toolResults }) => {
          onStepFinishCalls.push({ toolCalls, toolResults });
        },
      },
    });

    // When: Using streamWithEvents with tool execution
    const events = await collectEvents(agent, "Use test_tool with input 'test'", 2);

    // Then: User's callback should be called
    expect(onStepFinishCalls.length).toBeGreaterThan(0);
    expect(events.some((e) => e.type === "step-finish")).toBe(true);
  });

  test("applies custom stopWhen conditions in streaming", async () => {
    // Given: Agent with custom stop condition
    let stepCount = 0;
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      loopControl: {
        stopWhen: () => {
          stepCount++;
          return stepCount >= 2; // Stop after 2 steps
        },
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Count to 5", 5);

    // Then: Should stop at custom condition
    expect(events.length).toBeLessThan(10); // Should stop early
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("executes prepareStep before each step", async () => {
    // Given: Agent with prepareStep callback
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      loopControl: {
        prepareStep: async ({ stepNumber }) => {
          prepareStepCalls.push({ stepNumber });
          return {};
        },
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: prepareStep should be called
    expect(prepareStepCalls.length).toBeGreaterThan(0);
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("calls onFinish after completion", async () => {
    // Given: Agent with onFinish callback
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      loopControl: {
        onFinish: async ({ response, steps }) => {
          onFinishCalls.push({ response, steps });
        },
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: onFinish should be called once
    expect(onFinishCalls.length).toBe(1);
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("preserves checkpointing with user callbacks", async () => {
    // Given: Agent with both checkpointing and user callback
    const mockCheckpointer = {
      save: async (checkpoint: any) => {
        // Mock checkpoint save
      },
      load: async () => undefined,
      list: async () => [],
      delete: async () => {},
      exists: async () => false,
    };
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      checkpointer: mockCheckpointer,
      loopControl: {
        onStepFinish: async () => {
          onStepFinishCalls.push("called");
        },
      },
    });

    // When: Using streamWithEvents with threadId
    const events = [];
    for await (const event of agent.streamWithEvents({
      prompt: "Say hello",
      threadId: "test-thread",
      maxSteps: 1,
    })) {
      events.push(event);
      if (event.type === "done") break;
    }

    // Then: Both checkpointing and user callback should work
    expect(onStepFinishCalls.length).toBeGreaterThan(0);
    expect(events.some((e) => e.type === "checkpoint-saved")).toBe(true);
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("combines all callbacks correctly", async () => {
    // Given: Agent with all callback types
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      tools: { test: createMockTool("test") },
      loopControl: {
        prepareStep: async () => {
          prepareStepCalls.push("prepare");
          return {};
        },
        onStepFinish: async () => {
          onStepFinishCalls.push("finish");
        },
        onFinish: async () => {
          onFinishCalls.push("complete");
        },
        stopWhen: () => prepareStepCalls.length >= 2,
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Use test tool", 3);

    // Then: All callbacks should execute
    expect(prepareStepCalls.length).toBeGreaterThan(0);
    expect(events.some((e) => e.type === "done")).toBe(true);
  });
});

// ============================================================================
// Phase 3: Telemetry for Summarization
// ============================================================================

describe("Phase 3: Summarization Telemetry", () => {
  let backend: StateBackend;

  beforeEach(() => {
    backend = new StateBackend({ todos: [], files: {} });
  });

  test("passes telemetry to summarization generateText", async () => {
    // Given: Agent with telemetry and summarization enabled
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      summarization: {
        enabled: true,
        tokenThreshold: 100, // Low threshold to trigger summarization
        keepMessages: 2,
      },
      advancedOptions: {
        experimental_telemetry: { isEnabled: true },
        providerOptions: { anthropic: {} },
      },
    });

    // When: Sending long conversation that triggers summarization
    const longPrompt = "A".repeat(200); // Long message
    const events = await collectEvents(agent, longPrompt, 1);

    // Then: Should complete without errors (telemetry passed to summarization)
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("includes provider options in summarization", async () => {
    // Given: Agent with provider options and summarization
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      summarization: {
        enabled: true,
        tokenThreshold: 100,
        keepMessages: 2,
      },
      generationOptions: {
        temperature: 0.5,
        maxRetries: 2,
      },
    });

    // When: Triggering summarization
    const events = await collectEvents(agent, "B".repeat(200), 1);

    // Then: Should complete with generation options applied
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("applies generation options to summarization", async () => {
    // Given: Agent with generation options and summarization
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      summarization: {
        enabled: true,
        tokenThreshold: 100,
        keepMessages: 2,
      },
      advancedOptions: {
        experimental_context: { mode: "summarization" },
      },
    });

    // When: Triggering summarization
    const events = await collectEvents(agent, "C".repeat(200), 1);

    // Then: Should complete successfully
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("works without telemetry options in summarization", async () => {
    // Given: Agent with summarization but no telemetry
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      summarization: {
        enabled: true,
        tokenThreshold: 100,
        keepMessages: 2,
      },
    });

    // When: Triggering summarization
    const events = await collectEvents(agent, "D".repeat(200), 1);

    // Then: Should work normally
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("preserves summarization configuration with telemetry", async () => {
    // Given: Agent with custom summarization config
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend,
      summarization: {
        enabled: true,
        tokenThreshold: 150,
        keepMessages: 3,
        model: anthropic("claude-haiku-4-5-20251001"),
      },
      advancedOptions: {
        experimental_telemetry: { isEnabled: true },
      },
    });

    // When: Using agent with long content
    const events = await collectEvents(agent, "E".repeat(180), 1);

    // Then: Should apply custom config and telemetry
    expect(events.some((e) => e.type === "done")).toBe(true);
  });
});

// ============================================================================
// Integration Tests
// ============================================================================

describe("Integration: Complete Telemetry Flow", () => {
  test("end-to-end telemetry with streaming and summarization", async () => {
    // Given: Fully configured agent
    const integrationTool = createMockTool("integration_tool");
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend: new StateBackend({ todos: [], files: {} }),
      tools: { integrationTool },
      summarization: {
        enabled: true,
        tokenThreshold: 1000,
        keepMessages: 2,
      },
      generationOptions: { temperature: 0.7 },
      advancedOptions: {
        experimental_telemetry: { isEnabled: true },
        providerOptions: { anthropic: {} },
      },
      loopControl: {
        onStepFinish: async () => {
          // Mock callback
        },
      },
    });

    // When: Performing complex operation
    const events = await collectEvents(
      agent,
      "Use integrationTool with input 'test' and then summarize this long conversation: " +
        "F".repeat(500),
      3
    );

    // Then: All features should work together
    expect(events.some((e) => e.type === "text")).toBe(true);
    expect(events.some((e) => e.type === "step-finish")).toBe(true);
    expect(events.some((e) => e.type === "done")).toBe(true);
  });
});

// ============================================================================
// Edge Cases and Error Scenarios
// ============================================================================

describe("Edge Cases", () => {
  test("handles empty options objects", async () => {
    // Given: Agent with empty options
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend: new StateBackend({ todos: [], files: {} }),
      generationOptions: {},
      advancedOptions: {},
      loopControl: {},
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: Should work without errors
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("preserves maxSteps with loopControl.stopWhen", async () => {
    // Given: Agent with both maxSteps and stopWhen
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend: new StateBackend({ todos: [], files: {} }),
      loopControl: {
        stopWhen: () => false, // Never stop through this condition
      },
    });

    // When: Using streamWithEvents with maxSteps
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: Should respect maxSteps safety limit
    expect(events.some((e) => e.type === "done")).toBe(true);
  });

  test("handles callback errors gracefully", async () => {
    // Given: Agent with error-throwing callback
    const agent = createDeepAgent({
      model: anthropic("claude-haiku-4-5-20251001"),
      backend: new StateBackend({ todos: [], files: {} }),
      loopControl: {
        onStepFinish: async () => {
          throw new Error("Callback error");
        },
      },
    });

    // When: Using streamWithEvents
    const events = await collectEvents(agent, "Say hello", 1);

    // Then: Should handle error gracefully
    // Note: Actual error handling behavior depends on implementation
    expect(events.length).toBeGreaterThan(0);
  });
});